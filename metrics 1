import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

actual = numpy.array([1,1,1,1,1,1,0,0,0,0,0,0,
                      1,1,1,1,1,1,0,0,0,0,0,0,
                      1,1,1,1,1,1,0,0,0,0,0,0,
                      1,1,1,1,1,0,0,0,0,0,0,0,
                      1,1,1,1,1,1,0,0,0,0,0,0,
                      1,1,1,1,1,1,0,0,0,0,0,0,
                      1,1,1,1,1,1,0,0,0,0,0,0,
                      1,1,1,1,1,1,0,0,0,0,0,0,
                      1,1,1,1,1,1,0,0,0,0,0,0,
                      1,1,1,1,1,1,0,0,0,0,0,0,
                      1,1,1,1,1,1,0,0,0,0,0,0])
predicted = numpy.array([1,1,0,1,0,1,0,0,1,0,1,0,
                      1,1,0,1,0,1,0,0,1,0,1,0,
                      1,1,1,1,1,1,0,0,1,0,0,0,
                      1,1,0,1,1,0,0,0,1,0,0,0,
                      1,1,0,1,0,1,1,0,1,0,0,0,
                      0,0,0,1,1,1,0,0,0,0,1,0,
                      1,1,1,1,1,1,1,0,0,0,0,0,
                      1,0,1,1,1,1,0,0,1,0,1,0,
                      1,1,0,1,1,1,0,0,1,0,0,1,
                      0,1,0,1,1,1,0,0,0,1,0,0,
                      1,1,1,0,1,1,0,0,1,1,0,1])
confusion_matrix = metrics.confusion_matrix(actual, predicted)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[0, 1])

cm_display.plot()
plt.show()
Accuracy = metrics.accuracy_score(actual, predicted)
Precision = metrics.precision_score(actual, predicted)

Sensitivity_recall = metrics.recall_score(actual, predicted)
Specificity = metrics.recall_score(actual, predicted, pos_label=0)
F1_score = metrics.f1_score(actual, predicted)
print({"Accuracy": Accuracy,"Precision": Precision,"Sensitivity_recall": Sensitivity_recall,"Specificity": Specificity,"F1_score":F1_score})
